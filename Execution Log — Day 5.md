# Day 5 - 19/02/26 — Side Quest (AI Core)

## Topic: AI Fundamentals — Training vs Inference

### 1. What AI Actually Is (Layer 0)

Understood that modern AI models are not intelligent entities.
They are numerical systems that map inputs to outputs using learned parameters (weights).

Key Insight:
AI = Input → Numerical transformation → Output  
No consciousness. No reasoning. Just math.

---

### 2. Normal Program vs AI Model

Normal Program:
- Behavior defined by explicit human-written rules.
- Logic is hardcoded.

AI Model:
- Behavior defined by learned numerical parameters.
- Rules are not written manually; they emerge from training data.

Key Insight:
Traditional software is rule-based.
AI systems are parameter-based.

---

### 3. Training vs Inference

Training:
- Weights are adjusted.
- Error is calculated.
- Learning happens.

Inference:
- Weights remain fixed.
- Only forward computation is performed.
- No learning occurs.

Key Insight:
Learning happens only during training.
Inference is execution of learned parameters.

---

### 4. Why Inference is Computationally Heavy

Even though weights do not change during inference:
- Millions or billions of parameters must be processed.
- Large-scale numerical operations are performed for every input.

Key Insight:
Inference is compute-heavy due to scale of numerical operations, not because the model is “thinking”.

---

### 5. What Makes a Model Appear Smart?

Identified four pillars:
- Quality of training data
- Model size (parameters)
- Architecture design
- Optimization process

Hardware enables scale but does not determine intelligence.

---

Status:
AI Core reset to foundational understanding.
No abstraction jumps.
Building from fundamentals upward.
